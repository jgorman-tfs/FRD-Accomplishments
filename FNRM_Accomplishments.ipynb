{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forest and Natural Resources Management Division Quarterly Accomplishments Script\n",
    "### This script is broken into 2 major parts: Urban and Community Forestry Stats and FNRM Accomplishments. Part 1 is used to find the total acres of and total number of communities assisted with UC&F. Part 2 is used to create the dot density map showing the quarterly accomplishments. More detailed information can be found in the README on GitHub. https://github.com/jgorman-tfs/FRD-Accomplishments\n",
    "\n",
    "### Side note for future readers - The division changed its name from FRD to FNRM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "#Quarter and fiscal year\n",
    "qtr = \"FY2026Q20\"\n",
    "#Set folder path to new quarter folder\n",
    "folder_path = rf'D:\\ArcGIS_Projects\\FRDAccomplishments\\{qtr}'\n",
    "accomp_from_access_path = rf\"D:\\ArcGIS_Projects\\FRDAccomplishments\\{qtr}\\Accomplishments.XLSX\"\n",
    "ucf_spreadsheet_path = rf\"D:\\ArcGIS_Projects\\FRDAccomplishments\\{qtr}\\Q1FY26_Urban_OG_TESTING.xlsx\"\n",
    "#This shapefile is provided in sharepoint. If your using your own, you MUST calculate a new field with the County names of each city.\n",
    "symbology_temp = r\"D:\\ArcGIS_Projects\\FRDAccomplishments\\SymbologyTemplate.lyrx\"\n",
    "cities = r\"D:\\ArcGIS_Projects\\FRDAccomplishments\\FRDAccomplishments.gdb\\Texas_Places_WithCounties\"\n",
    "gdb = r\"D:\\ArcGIS_Projects\\FRDAccomplishments\\FRDAccomplishments.gdb\"\n",
    "\n",
    "spam_sheet = \"spam_raw\"\n",
    "elmr_sheet = \"elmr_raw\"\n",
    "\n",
    "con_ed_activity_list = [\"Arbor Day Program\", \n",
    "                        \"UF Presentation\", \n",
    "                        \"Brochure/Web/Newsletter/Media\", \n",
    "                        \"Conference/Workshop/Training\", \n",
    "                        \"Education/Outreach Event or Presentation\",\n",
    "                        \"UF Training Given\",\n",
    "                        \"Arbor Day/Tree City USA Event\"\n",
    "                       ]\n",
    "ta_activity_list = [\"Tree Planting Event\",\n",
    "                    \"Tree Board or Group Activities\",\n",
    "                    \"UF Incidental Assist\",\n",
    "                    \"UF Individual Assist\",\n",
    "                    \"EAB and other Pest Detection/Planning\",\n",
    "                    \"Landscape Plan or Site-Specific Issue\",\n",
    "                    \"Management Plan\",\n",
    "                    \"Tree Inventory or Assessment\",\n",
    "                    \"Tree Planting/Maintenance Program\",\n",
    "                    \"Tree Ordinance/Policy\"\n",
    "                   ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 : Urban and Community Forestry Stats\n",
    "\n",
    "### <u><b>Before you begin:<b><u>\n",
    "### 1. Combine the SPAM and ELMR data into one workbook (xlxs). \n",
    "### 2. Make 2 sheets: <u><b> spam_raw and elmr_raw <b><u>\n",
    "### 3. Copy the city and activity name from the spam table into the spam_raw sheet \n",
    "### 4. Copy the office, county, and activity name from the ELMR table to elmr_raw. Change abbreviated offices to the full name (i.e KER -> Kerville\n",
    "\n",
    "### SPAM SHEET COLUMNS : City , Activity Name\n",
    "### ELMR SHEET COLUMNS: City, Activity Name, County"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the sheets into a single pandas df. Make sure the counts match up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = pd.read_excel(\n",
    "    ucf_spreadsheet_path,\n",
    "    sheet_name=[\"spam_raw\", \"elmr_raw\"],\n",
    "    usecols=[\"City\", \"Activity Name\"]\n",
    ")\n",
    "sheet_counts = {sheet: len(df) for sheet, df in dfs.items()}\n",
    "    \n",
    "df = (\n",
    "    pd.concat(dfs.values(), ignore_index=True)\n",
    ")\n",
    "\n",
    "print(df.head())\n",
    "# Count combined rows\n",
    "combined_count = len(df)\n",
    "expected_count = sum(sheet_counts.values())\n",
    "\n",
    "print(f\"\\nExpected total rows: {expected_count}\")\n",
    "print(f\"Actual combined rows: {combined_count}\")\n",
    "\n",
    "assert combined_count == expected_count, \"Row count mismatch!\"\n",
    "print(\"Row counts match\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the unique activity names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_activities = (\n",
    "    df[[\"Activity Name\"]]\n",
    "    .drop_duplicates()\n",
    "    .sort_values(\"Activity Name\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "print(unique_activities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map the activity type to the activity name. \n",
    "\n",
    "### Check to see which activities are not included. You should see General Public/Home/Phone Consultation and Informational Meeting Attended. It was decided that these are not to be included for now, however other categories may appear. Either use best judgement on where to include them or drop them or ask Gretchen/Melissa/Michelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Activity Type\"] = None\n",
    "\n",
    "df.loc[\n",
    "    df[\"Activity Name\"].isin(con_ed_activity_list),\n",
    "    \"Activity Type\"\n",
    "] = \"Conservation Education\"\n",
    "\n",
    "df.loc[\n",
    "    df[\"Activity Name\"].isin(ta_activity_list),\n",
    "    \"Activity Type\"\n",
    "] = \"Technical Assistance\"\n",
    "\n",
    "unmapped_counts = (\n",
    "    df[df[\"Activity Type\"].isna()][\"Activity Name\"]\n",
    "    .value_counts()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "unmapped_counts.columns = [\"Activity Name\", \"count\"]\n",
    "print(unmapped_counts)\n",
    "\n",
    "total_unmapped = unmapped_counts[\"count\"].sum()\n",
    "print(\"Total of activities to be dropped: \", total_unmapped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check to make sure the number of rows dropped is expected. This should be the total of unmapped rows minus the total rows of the original data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df.dropna(subset=[\"Activity Type\"]).reset_index(drop=True)\n",
    "assert combined_count - total_unmapped == len(df_filtered), \"Counts do not line up. The incorrect number of rows were dropped\"\n",
    "print(\"Counts are as expected\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Texas_PLaces_WithCounties layer as a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [\"CityName\", \"Acres\",\"CountyName\"]\n",
    "\n",
    "# Convert to NumPy array\n",
    "arr = arcpy.da.TableToNumPyArray(cities, fields)\n",
    "feature_layer_df = pd.DataFrame(arr)\n",
    "\n",
    "print(feature_layer_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize city names to remove spaces and merge the city list with the Places layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered[\"City\"] = df_filtered[\"City\"].str.replace(\" \", \"\", regex=False)\n",
    "\n",
    "df_merged = df_filtered.merge(\n",
    "    feature_layer_df,\n",
    "    left_on=\"City\",      # column in df_filtered\n",
    "    right_on=\"CityName\", # column in feature_layer_df\n",
    "    how=\"left\"\n",
    ")\n",
    "df_merged = df_merged.drop(columns=[\"CityName\"])\n",
    "print(df_merged.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print out the cities that did not get matched. \n",
    "\n",
    "### It is expected to have a few because sometimes SPAM reports the county instead of the city. In that case, you can drop any Texas rows and rows that have counties instead of cities (i.e. Tarrant). There may also be misspellings. In that case you can adjust the spelling on the spreadsheet and run the cells again. \n",
    "\n",
    "### MAKE SURE YOU AGREE WITH THE LISTED CITIES TO BE DROPPED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unmatched_cities = (\n",
    "    df_merged[df_merged[\"Acres\"].isna()][\"City\"]\n",
    "    .value_counts()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "unmatched_cities.columns = [\"City\", \"count\"]\n",
    "\n",
    "print(unmatched_cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the unmatched cities to get a final dataframes; one for the full city list with duplicates (minus unmatched cities and activities) and one of the unique cities. Calculate the total acres assisted for unique cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucf_df_final = df_merged.dropna(subset=[\"Acres\"]).reset_index(drop=True) \n",
    "unique_cities = (\n",
    "    ucf_df_final[[\"City\",\"Acres\"]]\n",
    "    .drop_duplicates()\n",
    "    .sort_values(\"City\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "print(ucf_df_final.head())\n",
    "print(\"\\nTotal Cities with Duplicates: \", len(ucf_df_final))\n",
    "print(\"\\nTotal Unique Cities :\", len(unique_cities))\n",
    "total_acres = unique_cities[\"Acres\"].sum()\n",
    "print(\"\\nTotal Acres Assisted: \", total_acres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send the final dataframes to a single spreadsheet with a sheet for each df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_output_filename = f\"{qtr}_CityActivities.xlsx\"\n",
    "\n",
    "# Full path to the Excel file\n",
    "city_output_xlsx = os.path.join(folder_path, city_output_filename)\n",
    "\n",
    "# Write the Excel file with two sheets\n",
    "with pd.ExcelWriter(city_output_xlsx, engine=\"openpyxl\") as writer:\n",
    "    ucf_df_final.to_excel(writer, sheet_name=\"FinalCityListFull\", index=False)\n",
    "    unique_cities.to_excel(writer, sheet_name=\"UniqueCities\", index=False)\n",
    "\n",
    "print(f\"Excel file saved to: {city_output_xlsx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Accomplishments Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the SPAM sheet to a df. Normalize the City name column to remove spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_df = pd.read_excel(ucf_spreadsheet_path, sheet_name=spam_sheet)\n",
    "spam_df[\"City\"] = spam_df[\"City\"].str.replace(\" \", \"\", regex=False)\n",
    "spam_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the SPAM sheet to a df and merge into previously read feature_layer_df (Texas_Places_WithCounties). Check the printed list for names that are cities but didn't get matched. If its a spelling error, fix the source issue and re-read the df back in. If its a city that isn't listed on Texas_Places_WithCounties, add in the case in the next cell and change to name to the correct county. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_df_merged = spam_df.merge(\n",
    "    feature_layer_df[[\"CityName\", \"CountyName\"]],  # only keep relevant columns\n",
    "    left_on=\"City\",      # column in spam_df\n",
    "    right_on=\"CityName\", # column in feature_layer_df\n",
    "    how=\"left\"\n",
    ")\n",
    "unmatched_counties = (\n",
    "    spam_df_merged.loc[spam_df_merged[\"CountyName\"].isna(), \"City\"]\n",
    "    .value_counts()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"City\", \"City\": \"count\"})\n",
    ")\n",
    "\n",
    "print(\"Before fix:\")\n",
    "print(unmatched_counties)\n",
    "before_fix = spam_df_merged[[\"City\", \"CountyName\"]].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix the City/County name mix-ups accounting for special cases in the city_to_county dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_to_county = {\n",
    "    \"Texas\": \"Travis\",\n",
    "    \"Cypress\": \"Harris\",\n",
    "    \"Kingwood\": \"Harris\",\n",
    "    # add more special cases here\n",
    "}\n",
    "\n",
    "# Mask for rows with missing CountyName\n",
    "mask = spam_df_merged[\"CountyName\"].isna()\n",
    "\n",
    "# Apply mapping or default to city name\n",
    "spam_df_merged.loc[mask, \"CountyName\"] = (\n",
    "    spam_df_merged.loc[mask, \"City\"].map(city_to_county)  # map special cases\n",
    "    .fillna(spam_df_merged.loc[mask, \"City\"])            # default: city name\n",
    ")\n",
    "\n",
    "after_fix = spam_df_merged[[\"City\", \"CountyName\"]]\n",
    "\n",
    "changes = before_fix.copy()\n",
    "changes[\"CountyName_after\"] = spam_df_merged[\"CountyName\"]\n",
    "\n",
    "changes = changes[changes[\"CountyName\"] != changes[\"CountyName_after\"]]\n",
    "\n",
    "print(changes)\n",
    "spam_df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the ELMR sheet to a df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmr_df = pd.read_excel(ucf_spreadsheet_path, sheet_name = elmr_sheet)\n",
    "elmr_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate the ELMR and SPAM df's and get a total count of accomplishments to make sure they match up. You can verify this in the excel sheet if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmr_subset = (\n",
    "    elmr_df[[\"Activity Name\", \"County\"]]\n",
    "    .rename(columns={\"County\": \"CountyName\"})\n",
    ")\n",
    "elmr_count = len(elmr_subset)\n",
    "\n",
    "spam_subset = spam_df_merged[[\"Activity Name\", \"CountyName\"]]\n",
    "spam_count = len(spam_subset)\n",
    "\n",
    "ucf_accomp_df = pd.concat(\n",
    "    [elmr_subset, spam_subset],\n",
    "    ignore_index=True\n",
    ")\n",
    "ucf_accomp_total = len(ucf_accomp_df)\n",
    "\n",
    "print(\"Number of Accomplishments from ELMR: \", elmr_count)\n",
    "print(\"\\nNumber of Accomplishments from SPAM: \", spam_count)\n",
    "print(\"\\nNumber of Unfiltered Accomplishments: \", ucf_accomp_total)\n",
    "assert ucf_accomp_total == elmr_count + spam_count , \"The accomplishment totals do not add up. Check the df concatenation\"\n",
    "ucf_accomp_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map the acitivity names to activity types. Print out the unmapped activities and check to make sure you its okay to drop them. This step should be complete from Part 1 but this is just a double check. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucf_accomp_df[\"Activity Type\"] = None\n",
    "\n",
    "ucf_accomp_df.loc[\n",
    "    ucf_accomp_df[\"Activity Name\"].isin(con_ed_activity_list),\n",
    "    \"Activity Type\"\n",
    "] = \"Conservation Education\"\n",
    "\n",
    "ucf_accomp_df.loc[\n",
    "    ucf_accomp_df[\"Activity Name\"].isin(ta_activity_list),\n",
    "    \"Activity Type\"\n",
    "] = \"Technical Assistance\"\n",
    "\n",
    "   \n",
    "ucf_unmapped = ucf_accomp_df[ucf_accomp_df[\"Activity Type\"].isna()]\n",
    "ucf_unmapped_counts = (\n",
    "    ucf_unmapped[\"Activity Name\"]\n",
    "    .value_counts()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "ucf_unmapped_counts.columns = [\"Activity Name\", \"count\"]\n",
    "\n",
    "print(ucf_unmapped_counts)\n",
    "\n",
    "\n",
    "total_unmapped_ucf_accomp = ucf_unmapped_counts[\"count\"].sum()\n",
    "print(\"Total of activities to be dropped:\", total_unmapped_ucf_accomp)\n",
    "\n",
    "mapped_rows = ucf_accomp_df[\"Activity Type\"].notna().sum()\n",
    "unmapped_rows = ucf_accomp_df[\"Activity Type\"].isna().sum()\n",
    "print(\"\\nTotal rows:\", len(ucf_accomp_df))\n",
    "print(\"Mapped rows:\", mapped_rows)\n",
    "print(\"Unmapped rows:\", unmapped_rows)\n",
    "assert mapped_rows + unmapped_rows == len(ucf_accomp_df), \"Mapped rows and Unmapped Rows do not match\"\n",
    "ucf_accomp_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the unmapped activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucf_accomp_df_filtered = ucf_accomp_df.dropna(subset=[\"Activity Type\"]).reset_index(drop=True)\n",
    "print(\"Total number of filtered Accomplishments: \",len(ucf_accomp_df_filtered))\n",
    "assert len(ucf_accomp_df_filtered) == len(ucf_accomp_df) - unmapped_rows, \"Counts do not line up. The incorrect number of rows were dropped\"\n",
    "print(\"Counts are as expected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a count of the Technical Assistance accomplishments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta_counts = (\n",
    "    ucf_accomp_df\n",
    "    .loc[ucf_accomp_df[\"Activity Type\"] == \"Technical Assistance\"]\n",
    "    .groupby(\"CountyName\")\n",
    "    .size()\n",
    "    .reset_index(name=\"Technical Assistance\")\n",
    ")\n",
    "ta_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a count of the Con Ed accomplishments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_ed_counts = (\n",
    "    ucf_accomp_df\n",
    "    .loc[ucf_accomp_df[\"Activity Type\"] == \"Conservation Education\"]\n",
    "    .groupby(\"CountyName\")\n",
    "    .size()\n",
    "    .reset_index(name=\"Conservation Education\")\n",
    ")\n",
    "con_ed_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double check to see if there are any mismatches in the County Names of the previous two dfs (ta count and con ed count) and the access DB sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_df = pd.read_excel(accomp_from_access_path)\n",
    "access_counties = set(access_df[\"CountyName\"].unique())\n",
    "comparison_sets = {\n",
    "    \"Conservation Education\": set(con_ed_counts[\"CountyName\"].unique()),\n",
    "    \"Technical Assistance\": set(ta_counts[\"CountyName\"].unique())\n",
    "}\n",
    "# Check for missing counties\n",
    "missing_counties = {name: counties - access_counties for name, counties in comparison_sets.items()}\n",
    "\n",
    "# Print results\n",
    "if all(len(counties) == 0 for counties in missing_counties.values()):\n",
    "    print(\"No Missing Counties\")\n",
    "else:\n",
    "    for name, counties in missing_counties.items():\n",
    "        if counties:\n",
    "            print(f\"Counties in {name} missing from access_df: {counties}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine the ucf tables into accomplishments by county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_activity_wide = (\n",
    "    ucf_accomp_df\n",
    "    .pivot_table(\n",
    "        index=\"CountyName\",\n",
    "        columns=\"Activity Type\",\n",
    "        values=\"Activity Name\",\n",
    "        aggfunc=\"count\",\n",
    "        fill_value=0\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "total_activities_ucf = county_activity_wide.select_dtypes(\"number\").sum().sum()\n",
    "print(\"Total activities: \", total_activities_ucf)\n",
    "county_activity_wide.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the accomplishment sheet from the access db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_cols = [\"Conservation Education\", \"Management Plans\", \"Technical Assistance\", \"FIA Plots\"]\n",
    "total_activities = access_df[activity_cols].sum().sum()\n",
    "print(\"Total number of activities from access db:\", total_activities)\n",
    "print(\"Number of Rows:\", len(access_df))\n",
    "assert len(access_df) == 254, \"Number of rows is not 254. There maybe duplicate entries in the table\"\n",
    "access_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine all three tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_df = access_df.merge(\n",
    "    county_activity_wide,\n",
    "    on=\"CountyName\",\n",
    "    how=\"left\",\n",
    "    suffixes=(\"\", \"_new\")  # keep original columns, new ones get _new\n",
    ")\n",
    "\n",
    "# Columns you want to sum\n",
    "cols_to_sum = [\"Conservation Education\", \"Technical Assistance\"]\n",
    "\n",
    "for col in cols_to_sum:\n",
    "    access_df[col] = access_df[col].fillna(0) + access_df[f\"{col}_new\"].fillna(0)\n",
    "access_df.drop(columns=[f\"{col}_new\" for col in cols_to_sum], inplace=True)\n",
    "access_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check to make sure the total counts add up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_accomplishment_count_expected = total_activities + total_activities_ucf\n",
    "print(\"Total Accomplishments Expected: \", final_accomplishment_count_expected)\n",
    "\n",
    "final_activity_cols = [\"Conservation Education\", \"Management Plans\", \"Technical Assistance\", \"FIA Plots\"]\n",
    "final_accomplishment_count_results = access_df[activity_cols].sum().sum()\n",
    "print(\"Total Accomplishments Calculated: \", final_accomplishment_count_results)\n",
    "\n",
    "assert final_accomplishment_count_expected == final_accomplishment_count_results, \"Accomplishment counts do not match. A county join may have failed or you ran the previous cell more than once\"\n",
    "print(\"\\nTotals are in agreement. Proceed to mapping\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new map and feature layer for the quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aprx = arcpy.mp.ArcGISProject(\"CURRENT\")\n",
    "counties_new = f\"{qtr}_Counties\"\n",
    "arcpy.FeatureClassToFeatureClass_conversion(f\"{gdb}\\\\{\"Template\"}\", gdb, counties_new)\n",
    "layer_path = os.path.join(gdb, counties_new)\n",
    "new_map = aprx.createMap(f\"{qtr}\")\n",
    "for lyr in new_map.listLayers():\n",
    "    if lyr.isBasemapLayer:\n",
    "        new_map.removeLayer(lyr)\n",
    "new_layer = new_map.addDataFromPath(layer_path)\n",
    "arcpy.management.ApplySymbologyFromLayer(new_layer, symbology_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the final table to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_csv_filename = f\"final_accomp_count_{qtr}.csv\"\n",
    "csv_path = os.path.join(folder_path, final_csv_filename)\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "access_df.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join the CSV to the new feature layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcpy.management.JoinField(\n",
    "    in_data=layer_path,\n",
    "    in_field=\"CountyName\",\n",
    "    join_table=csv_path,\n",
    "    join_field=\"CountyName\",\n",
    "    fields=\"'Conservation Education';'Management Plans';'Technical Assistance';'FIA Plots'\",\n",
    "    fm_option=\"NOT_USE_FM\",\n",
    "    field_mapping=None,\n",
    "    index_join_fields=\"NO_INDEXES\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the feature layer into a df for a final count check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_list = [\"Conservation_Education\", \"Management_Plans\",\"Technical_Assistance\",\"FIA_Plots\"]\n",
    "final_arr = arcpy.da.TableToNumPyArray(layer_path, fields_list)\n",
    "final_layer_df = pd.DataFrame(final_arr)\n",
    "final_check = final_layer_df.sum().sum()\n",
    "print(\"Total Accomplishments Final Check: \", final_check)\n",
    "assert final_check == final_accomplishment_count_results, \"Final results do not agree. Make sure the number of accomplishments in the feature class matches Total Accomplishments Calculated\"\n",
    "print(\"Final Check Passed. Good to Continue\")\n",
    "final_layer_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the layout and update the contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year and quarter number\n",
    "fy = qtr[:2]            # \"FY\"\n",
    "year = qtr[2:6]         # \"2026\"\n",
    "quarter = qtr[-1]       # \"1\"\n",
    "\n",
    "# Combine into new format\n",
    "formatted_qtr = f\"{fy} {year} - Quarter {quarter}\"\n",
    "\n",
    "print(formatted_qtr)\n",
    "# Output: FY 2026 - Quarter 1\n",
    "layout = aprx.listLayouts(\"LayoutTemplate\")[0]\n",
    "\n",
    "map_frame = layout.listElements(\"MAPFRAME_ELEMENT\")[0]\n",
    "map_frame.map = new_map\n",
    "title_elem = next((t for t in layout.listElements(\"TEXT_ELEMENT\") if t.name == \"Text 1\"), None)\n",
    "if title_elem:\n",
    "    title_elem.text = formatted_qtr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the map to PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pdf_path = os.path.join(folder_path, f\"Quarterly_Accomplishments_{qtr}.pdf\")\n",
    "layout.exportToPDF(output_pdf_path, resolution=300)\n",
    "\n",
    "print(f\"Layout updated and exported to {output_pdf_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DONE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
